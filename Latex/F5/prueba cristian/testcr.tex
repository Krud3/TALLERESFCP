\documentclass[12pt, a4paper]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{array}
\usepackage{listings}
\usepackage{amsfonts} 
\usepackage{xcolor} 
\usepackage[margin=1in]{geometry} 
\lstset{
    language=Scala,  % lenguaje de programación
    basicstyle=\ttfamily\small,  % estilo de la fuente del código
    numbers=left,  % posición de los números de línea
    numberstyle=\tiny\color{gray},  % estilo de los números de línea
    stepnumber=1,  % el paso entre dos números de línea
    numbersep=5pt,  % cómo de lejos están los números de línea del código
    backgroundcolor=\color{white},  % color de fondo
    showspaces=false,  % mostrar espacios añadiendo particular subrayado
    showstringspaces=false,  % subrayar espacios dentro de las cadenas
    showtabs=false,  % mostrar tabs dentro de las cadenas añadiendo particular subrayado
    frame=single,  % añade un marco al código
    rulecolor=\color{black},  % si no se establece, el color del marco será el del texto
    tabsize=2,  % tamaño de los tabs
    captionpos=b,  % posición del título de la tabla (t=top, b=bottom)
    breaklines=true,  % establecer si las líneas automáticas se rompen
    breakatwhitespace=false, 
    escapeinside={\%*}{*)},  % si quieres añadir LaTeX dentro de tu código
    keywordstyle=\color{blue},  % estilo de las palabras clave
    commentstyle=\color{olive},  % estilo de los comentarios
    stringstyle=\color{violet},  % estilo de las cadenas
}
\graphicspath{ {./images/} }
\title{
  \begin{figure}[th]
    \centering
    \includegraphics[width=0.2\textwidth]{Univalle}
  \end{figure}
  \textbf{Universidad del Valle
    \\{\Large Facultad de ingeniería}
  \\{\large Ingeniería en sistemas}}}
\author{Cristian David Pacheco Torres
  \\ 2227437
  \\ Juan Sebastian Molina Cuellar
  \\ 2224491}
\date{\today}

\begin{document}

{Taller 4: Colecciones y Expresiones For:
\\ El problema de la subsecuencia incremental de longitud máxima}
\newpage{}

\tableofcontents
\newpage{}
\section{Introducción}
\subsection{Preliminares}
Con el proposito de implementar diferentes algoritmos de multiplicación de matrices, tanto secuenciales, recursivos y paralelos, se nos otorgó a través del \textit{Taller 5: Multiplicación de matrices en paralelo}, la definicion matemática de las siguientes operaciones:
\begin{itemize}
  \item Transpuesta de una matriz.

    \[T: \mathbb{R}^{m \times n} \to \mathbb{R}^{n \times m} \label{eq:transpuesta} \]
  \begin{equation}
    T(A) = [a_{ji}]_{n \times m}
  \end{equation}
  
  Se denota como : $\textbf{A}^T$
  \item Producto punto de vectores.
\[
    \cdot: \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}
\]
  \begin{equation}
    \mathbf{u} \cdot \mathbf{v} = \sum_{i=1}^{n} u_i v_i
  \end{equation}
  Donde  "$\cdot$" denota la operacion binaria entre dos vectores $~\in \mathbb{R}^n$.
  \item Multiplicación de matrices.
  \begin{equation}
    C_{ij} = \sum_{k=1}^{n} A_{ik} \cdot B_{kj}
  \end{equation}
  \item Suma de matrices.
\[
    +: \mathbb{R}^{m \times n} \times \mathbb{R}^{m \times n} \to \mathbb{R}^{m \times n}
\]
\[
    A + B = C
\]
  \begin{equation}
    C_{ij} = A_{ij} + B_{ij}
  \end{equation}
  Donde "$+$" representa la operación de adición entre dos matrices $~\in \mathbb{R}^{m \times n}$.
  A y B son las matrices a sumar.
  C es la matriz resultante de la suma.
  \item Resta de matrices.
\[
    -: \mathbb{R}^{m \times n} \times \mathbb{R}^{m \times n} \to \mathbb{R}^{m \times n}
\]
  \begin{equation}
    C_{ij} = A_{ij} - B_{ij}
  \end{equation}
\[
    A - B = C
\]
\end{itemize}
\textbf{Definiciones de utilidad:}\\ \\
Sea una tarea computacional $T=(t,r)$, donde $t$ es el tiempo de ejecución y $r$ el resultado.\\
Además definase dos funciones sobre $T$ como:
\begin{equation}
     \rho(T)= \rho(t,r) = r
\end{equation}
\begin{equation}
      \phi(T)= \phi(t,r) = t
\end{equation}
Definase una computación secuencial $S$: 
\begin{equation}
    S=<T_1,T_2,...T_i,...,T_{n-1},T_{n}>
\end{equation}
Donde $i$ representa el orden de ejecución de la tarea $T_i~ |~  0 \leq i \leq n$.\\ \\
Definase una computación paralela $P$:
\begin{equation}
    P=\{T_1,T_2,...T_i,...,T_{n-1},T_{n}\}
\end{equation}
Donde $i$ identifica cada tarea que a posteriori se le extraerá el tiempo de ejecución y el resultado.\\ \\
Sea $\phi(S)$ el tiempo de ejecución de una secuencia $S$:
\begin{equation}
    \phi(S)= \sum_{1}^{n}\phi(T_i)
\end{equation}
Sea $\phi(T)$ el tiempo de ejecución del conjunto de tareas $P$:
\begin{equation}
    \phi(P)= \max (\phi_i(T_i)) ~ | ~ 1 \leq i \leq n \land \phi_i(T_i) \in P
\end{equation}
\subsection{Algoritmos de proporcionados de utilidad}
En el listing \ref{lst:scala_code1}, se definen dos tipos de datos esenciales: \texttt{Matriz} y \texttt{MatrizD}. Estos tipos representan matrices de enteros, donde \texttt{MatrizD} está diseñada para un procesamiento paralelo en base al tipo $ParVector$ de $Scala$.

\begin{lstlisting}[caption=Definiciones tipos de datos, label=lst:scala_code1]
type Matriz = Vector[Vector[Int]]
type MatrizD = ParVector[ParVector[Int]]
\end{lstlisting}
\begin{lstlisting}[caption=matriz al azar, label=lst:scala_code2]
def matrizAlAzar(long:Int, vals:Int) = {
    //Crea una matriz de enteros cuadrada de long x long,
    //con valores entre 0 y vals
    val v = Vector.fill(long, long){random.nextInt(vals)}
    v
}
\end{lstlisting}
\begin{lstlisting}[caption=vector al azar, label=lst:scala_code3]
def vectorAlAzar(long:Int, vals:Int): Vector[Int] = {
    //Crea un vector de enteros de longitud long,
    //con valores aleatorios entre 0 y vals
    val v = Vector.fill(long){random.nextInt(vals)}
    v
}
\end{lstlisting}
\begin{lstlisting}[caption=producto punto, label=lst:scala_code4]
def prodPunto(v1: Vector[Int], v2: Vector[Int]): Int = {
    //Calcula el producto punto entre dos vectores
    (v1 zip v2).map({case (i,j) => i*j}).sum
}
\end{lstlisting}
\begin{lstlisting}[caption=transpuesta de una matriz, label=lst:scala_code5]
def transpuesta(m: Matriz): Matriz = {
    //Calcula la transpuesta de una matriz
    val l =m.length
    Vector.tabulate(l,l)((i,j)=>m(j)(i))
}
\end{lstlisting}

Los algoritmos anteriores fueron sugeridos en el $Taller 5$ por parte del profesor, para la implementación de las funciones a desarrollar en este informe. Estos algoritmos fueron de utilidad para generar matrices aletorias y operaciones fundamentales entre vectores.

\section{Informe del taller - secciones}
\subsection{Informe de corrección}
\textbf{{multMatriz}} \\ \\
\begin{lstlisting}[caption=mult matriz, label=lst:scala_code6]
def multMatriz(m1: Matriz, m2: Matriz): Matriz = {
    val l = m1.length
    val m = m2.length
    val v =Vector.tabulate(l,m)((i,j)=>prodPunto(m1(i),transpuesta(m2)(j)))
    v
}
\end{lstlisting}
Sea $m_1$ $m_2"$ $\in \mathbb{R}^{n \times n}$, dos matrices a aplicar el operador binario definido en (3), entonces,
por medio del método de sustitución se quiere demostrar que la implementación es equivalente de (3). Se tiene, además,
i, l representa los tamaños de $m_1$, $m_2$, respectivmente; prodPunto definido (2) y la transformación transpuesta trapose definida como (1); llamese la funcón traspose como $t()$, esto por simplicidad y ahorro de espacio: por tanto
    
\begin{math} m_1 \cdot m_2 = \text{{multMatriz}}(m_1, m_2) \\ \rightarrow
    \text{{Vector.tabulate}}(l, n)((i, j) \Rightarrow \text{{prodPunto}}(m_1[i], \text{{transpose}}(m_2)[j])) \\ \\
    \twoheadrightarrow \begin{bmatrix}
        m_1[0][0] \cdot \text{{t}}(m_2)[0][0] +  m_1[0][1] \cdot \text{{t}}(m_2)[1][0]  + 
       \ldots +  m_1[0][n-1] ~~~~~~~~~~ \ldots\\
         \vdots ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \ddots ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \vdots \\
         \ldots ~~~~~~m_1[n-1][1] \cdot \text{{t}}(m_2)[1][n-1] + \ldots + m_1[l-1][n-1] \cdot \text{{t}}(m_2)[l-1][n-1] \\
        \end{bmatrix} \\
\end{math}\\ \\
$ =~\sum_{k=0}^{n-1} m_{ik} \cdot t_{kj}^T$ \\
$= m_1 \cdot m_2$
\\ $\therefore ~~~m_1 \cdot m_2 =\text{{multMatriz}}(m_1, m_2)$ \\ \\

\textbf{{multMatrizPar}} \\ \\
\begin{lstlisting}[caption=mult matriz paralela, label=lst:scala_code7]
def multMatrizPar(m1: Matriz, m2: Matriz): Matriz = {
    val l = m1.length
    val m = m2.length
    val parRows = for (k <- 0 until l ) 
        yield {
            (k,task(Vector.tabulate(1,m)((i,j)=>
                prodPunto(m1(k),transpuesta(m2)(j)))))
        }
    val v = parRows.map({case (i,j) => 
        (i,j.join())}).sortBy(_._1).map(_._2)
    v.reduce(_++_)
}
\end{lstlisting}
Sea $m_1$ $m_2$ $\in \mathbb{R}^{n \times n}$, dos matrices a aplicar el operador binario definido en (3) en forma paralela, es decir,
en sentido en que se puede realizar los calculos de las partes unos independientes de otros y de forma simultanea, ya sea por un agente, o por varios, por medio de una
tarea computacional $T = (t, r)$; entonces, por medio del método de sustitución se quiere demostrar que la implementación es equivalente de (3). Se tiene, además,
i, l representa los tamaños de $m_1$, $m_2$, respectivamente; prodPunto definido (2) y la transformación transpuesta trapose definida como (1); llamese la funcón traspose como $t()$, esto por simplicidad y ahorro de espacio: por tanto
    
Definase $r_i$ = [~$\sum_{j=1}^{n} m_1[i][j] \cdot m_2[j][i]$~] como la $i$-séptima fila de $C$, $C_i$.
Luego, \\
\begin{math}
   m_1 \cdot m_2 = \begin{bmatrix}
       r_1 \\
       \vdots \\
       r_i \\
       \vdots \\
       r_n
        \\
    \end{bmatrix}
\end{math} \\
esto es, se tiene n matrices $r_i$  $\in \mathbb{R}^{1 \times n}.$ \\
Si se define un objecto agendamiento $A = (i, T)$ que representa un tarea T relacionado con un entero $i~| 1 \leq i \leq n$, 
asociado con los correspondientes indices i's de $r_i$, posiblemente azaroso pero culminada en un tiempo finito $\phi(T_i)$\\
Si para las $n~r_i \in \mathbb{R}^{1 \times n}$, procedemos como en la subsesion 2.1, se tiene \\
\begin{math} r_i = \text{{multMatriz}}(m_1[i], m_2[1..n][i]) \\ \rightarrow
    \text{{Vector.tabulate}}(1, n)((i, j) \Rightarrow \text{{prodPunto}}(m_i[1], \text{{transpose}}(m_2)[j])) \\
    \twoheadrightarrow r_i =[~\sum_{k=1}^{n} m_{ik} \cdot t_{kj}^T]
\end{math}\\
$\rightarrow r_i = m_1[i] \cdot m_2$
\\ $\therefore ~~~m_1[i] \cdot m_2 =\text{{multMatriz}}(m_1[i], m_2)$ \\
Se sabe que \\
$A = (i, T_i)$ representa cada cómputo, los cuales son linealmente independientes, también \\
$\rho(T_i) = r_i$ representa el resultado de la tarea $T_i,~r_i$, con $i$ siendo la $i$-ésima fila de $m_1$. \\
Por tanto, si se combinan los n resultados $r_i$ por el orden impuesto por $i$, primer elemento de la tupla de asignación $A_i$, en el sentido de formar una matriz a partir de la $n$ filas, se llega \\
$\therefore~~~$ \begin{math}
 m_1 \cdot m_2 = \begin{bmatrix}
        \rho(T_1) \\
        \vdots \\
        \rho(T_i) \\
        \vdots \\
        \rho(T_n) 
         \\
     \end{bmatrix} \equiv
    \begin{bmatrix}
        r_1 \\
        \vdots \\
        r_i \\
        \vdots \\
        r_n 
         \\
     \end{bmatrix}
 \end{math} \\ \\
\textbf{{multMatrizRec}} \\ \\
\begin{lstlisting}[caption=mult matriz recursiva, label=lst:scala_code8]
def multMatrizRec(m1:Matriz, m2:Matriz): Matriz ={
    //recibe m1 y m2 matrices cuadradas de la misma dimension, potencia de 2
    //y devuelve la multiplicacion de las 2 matrices
    val n = m1.length
    if(n == 1) {
        Vector(Vector(m1(0)(0)*m2(0)(0)))
    }
    else {
        val l = n/2
        val (m1_11, m1_12, m1_21, m1_22) = 
            (subMatriz(m1,0,0,l),subMatriz(m1,0,l,l),
             subMatriz(m1,l,0,l),subMatriz(m1,l,l,l))
        val (m2_11, m2_12, m2_21, m2_22) =
            (subMatriz(m2,0,0,l),subMatriz(m2,0,l,l),
             subMatriz(m2,l,0,l),subMatriz(m2,l,l,l))

        val c_11 = sumMatriz(multMatrizRec(m1_11,m2_11),multMatrizRec(m1_12,m2_21))
        val c_12 = sumMatriz(multMatrizRec(m1_11,m2_12),multMatrizRec(m1_12,m2_22))
        val c_21 = sumMatriz(multMatrizRec(m1_21,m2_11),multMatrizRec(m1_22,m2_21))
        val c_22 = sumMatriz(multMatrizRec(m1_21,m2_12),multMatrizRec(m1_22,m2_22))

        Vector.tabulate(n,n)((i,j)=>
            if(i<l && j<l) c_11(i)(j)
            else if(i<l && j>=l) c_12(i)(j-l)
            else if(i>=l && j<l) c_21(i-l)(j)
            else c_22(i-l)(j-l))
    }
}
\end{lstlisting}

Sea dos matrices, $m_1$ y $m_2$ $\in \mathbb{R}^{n \times n}$, y la multiplicación entre estas definido por (3), tal que $|m_1|, |m_2| = 2^k~|~ k \in N^+$, se quiere probar que 
la función implementada en $Scala$ $multMatrizRec$ son equivalentes.

\begin{itemize}
    \item \textbf{Caso base (n = 1)}: Si la matriz $m \in \mathbb{R}^{1 \times 1}$ (el caso base), el algoritmo realiza una multiplicación de dos escalares, y retorna el resultado envuelto en una matriz $m_r \in \mathbb{R}^{1 \times 1}$.
    \[
    \text{Si } n = 1 \quad \rightarrow \quad \begin{bmatrix} m_1[0][0] \cdot m_2[0][0] \end{bmatrix}
    \]

    \item \textbf{Caso recursivo $n \geq 2$}: Si $|m_1| \land |m_2| = k \geq 2$, se divide cada matriz, $m_1$ y $m_2$, en 4 submatrices de igual tamaño $m{{1{11}}}$, $m{{1{12}}}$, $m{{1{21}}}$, $m{{1{22}}}$, $m{{2{11}}}$, $m{{2{12}}}$, $m{{2{21}}}$, y $m{{2{22}}}$.
    Éste es paso $divide$ en la estraégia $divide~y~conquistaras$. \\
    Luego, después de que cada llamada recursiva haya retornado, se computan la suma de los productos respectivas submatrices (La definición de esta operación esta propuesta en el especificación del laboratorio, entonces se tomará como axioma, y se utilizará su resultado):
    
    \begin{align*}
    c_{11} &= \text{{multMatrizRec}}(m{{1{11}}}, m{{2{11}}}) + \text{{multMatrizRec}}(m{{1{12}}}, m{{2{21}}}) \\
    c_{12} &= \text{{multMatrizRec}}(m{{1{11}}}, m{{2{12}}}) + \text{{multMatrizRec}}(m{{1{12}}}, m{{2{22}}}) \\
    c_{21} &= \text{{multMatrizRec}}(m{{1{21}}}, m{{2{11}}}) + \text{{multMatrizRec}}(m{{1{22}}}, m{{2{21}}}) \\
    c_{22} &= \text{{multMatrizRec}}(m{{1{21}}}, m{{2{12}}}) + \text{{multMatrizRec}}(m{{1{22}}}, m{{2{22}}}) \\
    \end{align*}
    
    Para el paso $conquistaras$ en la estraégia $divide~y~conquistaras$, las matrices $c_{11}$, $c_{12}$, $c_{21}$, and $c_{22}$ se combinan para formar una matriz $m_r$ $\in \mathbb{R}^{2k \times 2k}$:
    
    
    \begin{align*}
    \text{{$m_r$}}[i][j] =
    \begin{cases}
        c_{11}[i][j] & \text{{si }} i < l \text{{ $\land$ }} j < l \\
        c_{12}[i][j-l] & \text{{si }} i < l \text{{ $\land$ }} j \geq l \\
        c_{21}[i-l][j] & \text{{si }} i \geq l \text{{ $\land$ }} j < l \\
        c_{22}[i-l][j-l] & \text{{si }} i \geq l \text{{ $\land$ }} j \geq l \\
    \end{cases}
    \end{align*}
    
    Donde cada combinación de subíndices determinados por la condiciones guardas en los casos, determina el valor
    $m_r[i][j]$, y representa la región del cuadrante donde va a ser dispuesta cada una de las cuatro  $c_{11}[i][j]$, $c_{12}[i][j-l]$, $c_{21}[i-l][j]$, $c_{22}[i-l][j-l]$ en el paso de la combinación para dar un matriz $|m_r|= k^2$

    \item \textbf{Invariantes}: 
    \begin{itemize}
        \item \textbf{Sobre el tamaño}: Las matrices $m_1, m_2$ cumple al comienzo de cada paso recursivo\\
        \[
          m_1, m_2~\in \mathbb{R}^{n-k \times n-k} \land |m_1|=|m_2|= 2^{n-k}, \quad k \in \mathbb{N}^+,\quad 0 \leq k \leq n 
        \] \\
        Nótese que \\ 
        \[ \lim_{k\to n} (n-k) = 0\]
        

        \item \textbf{Sobre la división en submatrices}: En cada llamada recursiva, divide una matriz de entrada en cuatro submatrices: $m{{1{11}}}$, $m{{1{12}}}$, $m{{1{21}}}$, $m{{1{22}}}$, $m{{2{11}}}$, $m{{2{12}}}$, $m{{2{21}}}$, y $m{{2{22}}}$. Esas submatrices representa $\frac{1}{4}$ de la matriz original
        y corresponde a una de las cuatro regiones dados por $k, k/2$ sobre el tamaño de sus filas y columnas.  
        
        \[
        \text{{Invariante: }} m1 = \begin{bmatrix} m{{1{11}}} & m{{1{12}}} \\ m{{1{21}}} & m{{1{22}}} \end{bmatrix}, \quad
        m2 = \begin{bmatrix} m{{2{11}}} & m{{2{12}}} \\ m{{2{21}}} & m{{2{22}}} \end{bmatrix}
        \]
        y $|m_{\{1,2\}}| = \frac{k-n}{2}$
        

        \item \textbf{Sobre la multiplicación}: Las llamadas recursivas a \text{multMatrizRec} son hechas sobre submatrices, y la tupla de resultados ($c_{11}$, $c_{12}$, $c_{21}$, $c_{22}$) son combinados de forma bien definida para retorna una matriz $m_r$ como resultado de la recursión. 
        La hipótesis inductiva asume que los producto de matrices se realiza de forma correcta en cada k-$esimo$ paso.
        
        \[
        \text{{Invariante: }} c_{ij} = \text{{multMatrizRec}}(m{{1{ij}}}, m{{2{ij}}})
        \]
        \item \textbf{Sobre la combinación}: La combinación de los productos de las submatrices forman la matriz resultado $m_r$, la posición esta definida de acuerdo a las guardas sobre los indices $i,j$ y corresponde a una región "$cartesiana$".
        La hipótesis innductiva asegura que cada submatriz es colocada en el cuadrate pertinente dentro de la matriz resultante.
        
        \[
        \text{{Invariante: }} m_r[i][j] = \begin{cases}
        c_{11}[i][j] & \text{{si }} i < l \land j < l \\
        c_{12}[i][j-l] & \text{{si }} i < l \land j \geq l \\
        c_{21}[i-l][j] & \text{{si }} i \geq l \land j < l \\
        c_{22}[i-l][j-l] & \text{{si }} i \geq l \land j \geq l \\
        \end{cases}
        \]

        \item \textbf{Sobre el caso base}: Se alcanza cuando $|m_{\{1,2\}}| = 1$. Por tanto, el algoritmo asegura tratar la matriz más pequeña posible
        para $n\geq 1$.
        
        \[
        \text{{Invariante: }} n = 1
        \]
    \end{itemize}
\end{itemize}


\textbf{{multMatrizRecPar}} \\ \\
\begin{lstlisting}[caption=mult matriz recursiva paralela, label=lst:scala_code9]
def multMatrizRecPar(m1:Matriz, m2:Matriz): Matriz ={
    //recibe m1 y m2 matrices cuadradas de la misma dimension, potencia de 2
    //y devuelve la multiplicacion de las 2 matrices, paralelizando tareas
    val n = m1.length
    if(n == 1) {
        Vector(Vector(m1(0)(0)*m2(0)(0)))
    }
    else {
        val l = n/2
        val (m1_11, m1_12, m1_21, m1_22) = 
            (subMatriz(m1,0,0,l),subMatriz(m1,0,l,l),
             subMatriz(m1,l,0,l),subMatriz(m1,l,l,l))
        val (m2_11, m2_12, m2_21, m2_22) =
            (subMatriz(m2,0,0,l),subMatriz(m2,0,l,l),
             subMatriz(m2,l,0,l),subMatriz(m2,l,l,l))
        val (c_11, c_12, c_21, c_22) = parallel(
            sumMatriz(multMatrizRec(m1_11,m2_11),
                      multMatrizRec(m1_12,m2_21)),
            sumMatriz(multMatrizRec(m1_11,m2_12),
                      multMatrizRec(m1_12,m2_22)),
            sumMatriz(multMatrizRec(m1_21,m2_11),
                      multMatrizRec(m1_22,m2_21)),
            sumMatriz(multMatrizRec(m1_21,m2_12),
                      multMatrizRec(m1_22,m2_22)))
        Vector.tabulate(n,n)((i,j)=>
            if(i<l && j<l) c_11(i)(j)
            else if(i<l && j>=l) c_12(i)(j-l)
            else if(i>=l && j<l) c_21(i-l)(j)
            else c_22(i-l)(j-l))
    }
}
\end{lstlisting}
La función \texttt{multMatrizRecPar} en Scala realiza la multiplicación de matrices de manera paralela y es equivalente a \texttt{multMatrizRec}, siguiendo los siguientes puntos clave:

\begin{enumerate}
    \item \textbf{Estructura y Pasos Básicos}: La función sigue la misma estructura lógica del algoritmo de multiplicación de matrices recursivo, que incluye:
    \begin{itemize}
        \item El caso base cuando $n = 1$, donde se realiza una multiplicación directa de escalares.
        \item El caso recursivo para $n \geq 2$, que implica dividir cada matriz en 4 submatrices y calcular las sumas de los productos de estas submatrices.
    \end{itemize}
    
    \item \textbf{Paralelización}: La principal diferencia en \texttt{multMatrizRecPar} es la paralelización de las operaciones. Utiliza \texttt{parallel} para ejecutar operaciones de forma concurrente, específicamente:
    \begin{itemize}
        \item Las multiplicaciones y sumas de submatrices \texttt{m1\_ij} y \texttt{m2\_ij} para calcular \texttt{c\_11}, \texttt{c\_12}, \texttt{c\_21}, \texttt{c\_22}.
    \end{itemize}

    \item \textbf{Mantenimiento de la Correctitud}: A pesar de la paralelización, la función conserva la lógica del método de multiplicación matricial y no altera el resultado final de las operaciones matemáticas.

    \item \textbf{Optimización y Eficiencia}: La paralelización mejora la eficiencia del algoritmo, especialmente para matrices grandes, reduciendo el tiempo total de ejecución y aprovechando mejor los recursos del sistema.
    \\ De manera formal, a partir de (10) y (11) se hace una comparación entre los tiempos de ejecución de un algoritmo implementado de forma secuencial y un algoritmo implementado de forma paralela.
     La idea es análoga al teoría de complejidad de funciones. Supongase que se tiene dos funciones que multiplica matrices, una de forma secuencial, cuya operaciones están dadas por 
     $S=<T_1,T_2,...T_i,...,T_{n-1},T_{n}>$ $n$ tareas $T$ secuenciales y otra de forma paralela $P=\{T_1,T_2,...T_i,...,T_{n-1},T_{n}\}$  de $n$ tareas $T$ paralelas. Entonces, 
    \[
     \exists~k_0~|~k_0 \in N^+~\land~n~\geq~k_0 \rightarrow ~\phi(P) \leq \phi(S) = \max (\phi_i(T_i)) \leq \sum_{1}^{n}\phi(T_i)   
    \]
    es decir, existe un número $k_0$, en este caso, un $k_0 = 2^k$ (por ser matrices cuadradas) tal que el tiempo de computo total pasa de ser la suma del tiempo de todas las tareas, en la ejecución secuencial, a
    ser igual al mayor tiempo de ejecución de una tarea del conjunto, en la forma paralela. Éste número $k_0$ depende de la instancia de ejecución, de los recursos disponibles, y, en este laboratorio, se le denominó
    $umbral$, cuyo valor determina el tamaño de la matriz en el cual el computo es más eficiente si se realiza una paralelización.
\end{enumerate}
\textbf{{multStrassen}} \\ \\
\begin{lstlisting}[caption=mult Strassen, label=lst:scala_cod10]
def multStrassen(m1:Matriz, m2:Matriz): Matriz ={
    //recibe m1 y m2 matrices cuadradas de la misma dimension, potencia de 2
    //y devuelve la multiplicacion de las 2 matrices
    val n = m1.length
    if(n == 1) {
        Vector(Vector(m1(0)(0)*m2(0)(0)))
    }
    else {           
        val l = n/2
        val (s1, s2, s3, s4, s5, s6, s7, s8, s9, s10) = (
            restaMatriz(subMatriz(m2,0,l,l),subMatriz(m1,l,l,l)),
            sumMatriz(subMatriz(m1,0,0,l), subMatriz(m1,0,l,l)),
            sumMatriz(subMatriz(m1,l,0,l), subMatriz(m1,l,l,l)),
            restaMatriz(subMatriz(m2,l,0,l), subMatriz(m2,0,0,l)),
            sumMatriz(subMatriz(m1,0,0,l), subMatriz(m1,l,l,l)),
            sumMatriz(subMatriz(m2,0,0,l), subMatriz(m2,l,l,l)),
            restaMatriz(subMatriz(m1,0,l,l), subMatriz(m1,l,l,l)),
            sumMatriz(subMatriz(m2,l,0,l), subMatriz(m2,l,l,l)),
            restaMatriz(subMatriz(m1,0,0,l), subMatriz(m1,l,0,l)),
            sumMatriz(subMatriz(m2,0,0,l), subMatriz(m2,0,l,l))
        )
        val (p1, p2, p3, p4, p5, p6, p7) = (
            multStrassen(subMatriz(m1,0,0,l), s1),
            multStrassen(s2, subMatriz(m2,l,l,l)),
            multStrassen(s3, subMatriz(m2,0,0,l)),
            multStrassen(subMatriz(m1,l,l,l), s4),
            multStrassen(s5, s6),
            multStrassen(s7, s8),
            multStrassen(s9, s10)
        )
        val (c_11, c_12, c_21, c_22) = (
            restaMatriz(sumMatriz(p5, p4), sumMatriz(p6, p2)),
            sumMatriz(p1, p2),
            sumMatriz(p3, p4),
            restaMatriz(sumMatriz(p1, p5), restaMatriz(p3, p7))
        )
        Vector.tabulate(n,n)((i,j)=>
            if(i<l && j<l) c_11(i)(j)
            else if(i<l && j>=l) c_12(i)(j-l)
            else if(i>=l && j<l) c_21(i-l)(j)
            else c_22(i-l)(j-l))
    }
}
\end{lstlisting}
\textbf{Multiplicación de matrices usando el método de Strassen}

Sea $m1$ y $m2$ matrices cuadradas de la misma dimensión, potencia de 2, y la función $multStrassen$ implementada en Scala. Se quiere demostrar que la función $multStrassen$ realiza la multiplicación de las matrices $m1$ y $m2$ utilizando el método de Strassen.

\begin{itemize}
    \item \textbf{Caso base $n = 1$}: Si la matriz $m$ $\in \mathbb{R}^{1 \times 1}$ (el caso base), el algoritmo realiza una multiplicación de dos escalares y retorna el resultado envuelto en una matriz $m_r$ $\in \mathbb{R}^{1 \times 1}$
    \[
    \text{{Si }} n = 1 \quad \rightarrow \quad \begin{bmatrix} m1[0][0] \cdot m2[0][0] \end{bmatrix}
    \]

    \item \textbf{Caso recursivo $n \geq 2$}: Si $|m1| \land |m2| = k \geq 2$, se divide cada matriz, $m1$ y $m2$, en 4 submatrices de igual tamaño: $m{{1{11}}}$, $m{{1{12}}}$, $m{{1{21}}}$, $m{{1{22}}}$, $m{{2{11}}}$, $m{{2{12}}}$, $m{{2{21}}}$, y $m{{2{22}}}$. 
    Este es el paso $divide$ en la estrategia $divide~y~venceras$. 
    Se genera díez matrices $s_i$ como resultado de operaciones aritméticas entre las ocho submatrices 
    generadas a partir de las matrices $m_1$ y $m_2$ de entrada:
    
    
    \begin{align*}
    s1 &= m2_{21} - m2_{11} \\
    s2 &= m1_{11} + m1_{12} \\
    s3 &= m1_{21} + m1_{22} \\
    s4 &= m2_{12} - m2_{22} \\
    s5 &= m1_{11} + m1_{22} \\
    s6 &= m2_{11} + m2_{22} \\
    s7 &= m1_{12} - m1_{22} \\
    s8 &= m2_{21} + m2_{22} \\
    s9 &= m1_{11} - m1_{21} \\
    s10 &= m2_{11} + m2_{12}
    \end{align*}
    
    Luego, se realizan siete llamadas recursivas (como se definió en el documento proporcionado como guía de laboratorio) a $multStrassen$ para calcular productos intermedios de forma recursiva:
    
    \begin{align*}
    p1 &= \text{{multStrassen}}(m1_{11}, s1) \\
    p2 &= \text{{multStrassen}}(s2, m2_{22}) \\
    p3 &= \text{{multStrassen}}(s3, m2_{11}) \\
    p4 &= \text{{multStrassen}}(m1_{22}, s4) \\
    p5 &= \text{{multStrassen}}(s5, s6) \\
    p6 &= \text{{multStrassen}}(s7, s8) \\
    p7 &= \text{{multStrassen}}(s9, s10)
    \end{align*}
    
    Finalmente, se combinan los resultados intermedios para formar la matriz resultado $m_r$:
    
    \begin{align*}
    c_{11} &= p5 + p4 - p2 + p6 \\
    c_{12} &= p1 + p2 \\
    c_{21} &= p3 + p4 \\
    c_{22} &= p5 + p1 - p3 - p7 \\
    \end{align*}

    \item \textbf{Invariantes}: 
    \begin{itemize}
        \item \textbf{Sobre el tamaño}: Las matrices $m1, m2$ cumplen al comienzo de cada paso recursivo\[
            m1, m2~\in \mathbb{R}^{n-k \times n-k} \land |m1|=|m2|= 2^{n-k}, \quad k \in \mathbb{N}^+,\quad 0 \leq k \leq n 
          \]
          Nótese que
          \[
            \lim_{k\to n} (n-k) = 0
          \]
          
        \item \textbf{Sobre la división en submatrices}: En cada llamada recursiva, se divide una matriz de entrada en cuatro submatrices: $m{{1{11}}}$, $m{{1{12}}}$, $m{{1{21}}}$, $m{{1{22}}}$, $m{{2{11}}}$, $m{{2{12}}}$, $m{{2{21}}}$ y $m{{2{22}}}$. Esas submatrices representan $\frac{1}{4}$ de la matriz original y corresponden a una de las cuatro regiones dadas por $k, k/2$ sobre el tamaño de sus filas y columnas.

        \[
        \text{{Invariante: }} m1 = \begin{bmatrix} m{{1{11}}} & m{{1{12}}} \\ m{{1{21}}} & m{{1{22}}} \end{bmatrix}, \quad
        m2 = \begin{bmatrix} m{{2{11}}} & m{{2{12}}} \\ m{{2{21}}} & m{{2{22}}} \end{bmatrix}
        \]
        y $|m_{\{1,2\}}| = \frac{k-n}{2}$

        \item \textbf{Sobre la multiplicación}: Las llamadas recursivas a \text{{multStrassen}} se hacen sobre submatrices, y la tupla de resultados ($s1, s2, \ldots, p7$) se combinan de forma bien definida para retornar una matriz $m_r$ como resultado de la recursión. La hipótesis inductiva asume que los productos de matrices se realizan de forma correcta en cada k-ésimo paso.

        \[
        \text{{Invariante: }} c_{ij} = \text{{multStrassen}}(m{{1{ij}}}, m{{2{ij}}})
        \]

        \item \textbf{Sobre la combinación}: La combinación de los productos de las submatrices forma la matriz resultado $m_r$, la posición está definida de acuerdo a las guardas sobre los índices $i,j$ y corresponde a una región "$cartesiana$". La hipótesis inductiva asegura que cada submatriz se coloca en el cuadrante pertinente dentro de la matriz resultante.

        \[
        \text{{Invariante: }} m_r[i][j] = \begin{cases}
        c_{11}[i][j] & \text{{si }} i < l \land j < l \\
        c_{12}[i][j-l] & \text{{si }} i < l \land j \geq l \\
        c_{21}[i-l][j] & \text{{si }} i \geq l \land j < l \\
        c_{22}[i-l][j-l] & \text{{si }} i \geq l \land j \geq l \\
        \end{cases}
        \]

        \item \textbf{Sobre el caso base}: Se alcanza cuando $|m_{\{1,2\}}| = 1$. Por tanto, el algoritmo asegura tratar la matriz más pequeña posible para $n \geq 1$.

        \[
        \text{{Invariante: }} n = 1
        \]
    \end{itemize}
\end{itemize}

\textbf{{multStrassenPar}} \\ \\
\begin{lstlisting}[caption=mult Strassen paralela, label=lst:scala_code11]
    def multStrassenPar(m1:Matriz, m2:Matriz): Matriz ={
        //recibe m1 y m2 matrices cuadradas de la misma dimension, potencia de 2
        //y devuelve la multiplicacion de las 2 matrices
        val n = m1.length
        
        /*if(umbral <= n){
            multMatrizRec(m1,m2)
        }*/
        if(n == 1) {
            Vector(Vector(m1(0)(0)*m2(0)(0)))
        }
        else {           
            val l = n/2
            val (s1, s2, s3, s4, s5, s6, s7, s8, s9, s10) = (
                restaMatriz(subMatriz(m2,0,l,l), 
                            subMatriz(m1,l,l,l)),
                sumMatriz(subMatriz(m1,0,0,l), 
                          subMatriz(m1,0,l,l)),
                sumMatriz(subMatriz(m1,l,0,l), 
                          subMatriz(m1,l,l,l)),
                restaMatriz(subMatriz(m2,l,0,l), 
                            subMatriz(m2,0,0,l)),
                sumMatriz(subMatriz(m1,0,0,l), 
                          subMatriz(m1,l,l,l)),
                sumMatriz(subMatriz(m2,0,0,l), 
                          subMatriz(m2,l,l,l)),
                restaMatriz(subMatriz(m1,0,l,l),
                            subMatriz(m1,l,l,l)),
                sumMatriz(subMatriz(m2,l,0,l),
                          subMatriz(m2,l,l,l)),
                restaMatriz(subMatriz(m1,0,0,l),
                            subMatriz(m1,l,0,l)),
                sumMatriz(subMatriz(m2,0,0,l),
                          subMatriz(m2,0,l,l))
            )
            val (p1, p2, p3, p4, p5, p6, p7) = (
                task(multStrassenPar(subMatriz(m1,0,0,l), s1)),
                task(multStrassenPar(s2, subMatriz(m2,l,l,l))),
                task(multStrassenPar(s3, subMatriz(m2,0,0,l))),
                task(multStrassenPar(subMatriz(m1,l,l,l), s4)),
                task(multStrassenPar(s5, s6)),
                task(multStrassenPar(s7, s8)),
                task(multStrassenPar(s9, s10))
            )
            val (c_11, c_12, c_21, c_22) = (
                restaMatriz(sumMatriz(p5.join(), p4.join()),sumMatriz(p6.join(), p2.join())),
                sumMatriz(p1.join(),p2.join()),
                sumMatriz(p3.join(),p4.join()),
                restaMatriz(sumMatriz(p1.join(), p5.join()),restaMatriz(p3.join(), p7.join()))
            )            
            Vector.tabulate(n,n)((i,j)=>
                if(i<l && j<l) c_11(i)(j)
                else if(i<l && j>=l) c_12(i)(j-l)
                else if(i>=l && j<l) c_21(i-l)(j)
                else c_22(i-l)(j-l))
        }
    }
\end{lstlisting}
La función \texttt{multStrassenPar} en Scala realiza la multiplicación de matrices utilizando el método de Strassen de manera paralela, siguiendo los siguientes puntos clave:

\begin{enumerate}
    \item \textbf{Estructura y Pasos Básicos}: La función sigue la misma estructura lógica del algoritmo de Strassen, incluyendo:
    \begin{itemize}
        \item El caso base cuando $n = 1$, donde se realiza una multiplicación directa de escalares.
        \item La división de las matrices en submatrices y el cálculo de las matrices intermedias $s1$ a $s10$.
        \item El cálculo de los productos $p1$ a $p7$ usando llamadas recursivas a \texttt{multStrassenPar}.
        \item La combinación de estos productos para formar la matriz resultante $m_r$.
    \end{itemize}
    
    \item \textbf{Paralelización}: Se introduce la paralelización mediante la función \texttt{task}, que inicia operaciones en hilos separados. Las operaciones clave paralelizadas son:
    \begin{itemize}
        \item El cálculo de $p1$ a $p7$, permitiendo ejecuciones simultáneas y mejorando la eficiencia en sistemas con múltiples núcleos.
        \item El uso de \texttt{join} en variables como \texttt{p1.join()}, asegurando que los resultados estén disponibles para los pasos subsiguientes.
    \end{itemize}

    \item \textbf{Mantenimiento de la Correctitud}: La paralelización no altera el orden de las operaciones matemáticas necesarias para el método de Strassen, manteniendo la correctitud del algoritmo.

    \item \textbf{Optimización y Eficiencia}: La paralelización está diseñada para mejorar la eficiencia del algoritmo, especialmente para matrices grandes, reduciendo el tiempo de ejecución en comparación con la versión secuencial.
    Nuevamente, como se argumento en la seción $multMatrizRecPar$, de (10) y (11) se hace una comparación entre los tiempos de ejecución de un algoritmo en forma secuencial y en forma paralela.
    Supongase una operación $m_1 \cdot m_2$ cuya ejecución $S$ 
    $S=<T_1,T_2,...T_i,...,T_{n-1},T_{n}>$ representa $n$ tareas $T$ secuenciales y otra ejecución paralela $P$ $P=\{T_1,T_2,...T_i,...,T_{n-1},T_{n}\}$  de $n$ tareas $T$ paralelas. De nuevo, 
   \[
    \exists~k_0~|~k_0 \in N^+~\land~n~\geq~k_0 \rightarrow ~\phi(P) \leq \phi(S) = \max (\phi_i(T_i)) \leq \sum_{1}^{n}\phi(T_i)   
   \]
   Existirá, por lo tanto, un número de tamaño de matriz, $k_0$, de modo que la ejecución en forma paralela tomará un tiempo de computor menor en la determinación del resultado $m_1 \cdot m_2$.
   De nuevo, éste es el umbral(en nuestro caso, $2^6$) buscado para condicionar el código y hacerlo más eficiente en las diferentes condiciones de ejecución. 
\end{enumerate}


\subsection{Informe de desempeño de las funciones secuenciales y de las funciones paralelas}
\subsubsection{Resultados de Multiplicación de Matrices}
Tabla comparativa y análisis de desempeño.

\begin{table}[h]
    \centering
    \begin{tabular}{ | m{2cm} | m{3cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & mulMatriz(ms) & multMatrizPar(ms) & speedup \\ 
    \hline
    $2^0$ & 0.0208 & 0.0126 & 1.65 \\
    $2^1$ & 0.054 & 0.0899 & 0.60 \\
    $2^2$ & 0.1658 & 0.2217 & 0.75 \\
    $2^3$ & 0.6989 & 1.003 & 0.70 \\
    $2^4$ & 2.2913 & 4.7724 & 0.48 \\
    $2^5$ & 2.8232 & 5.416 & 0.52 \\
    $2^6$ & 22.1308 & 36.1349 & 0.61 \\
    $2^7$ & 172.5227 & 249.1038 & 0.69 \\
    $2^8$ & 1391.6189 & 1747.6074 & 0.80 \\
    $2^9$ & 11624.2295 & 13095.9631 & 0.88 \\
    $2^{10}$ & 92733.1786 & 92184.1319 & 1.005 \\
    \hline
    \end{tabular}
    \caption{mulMatriz vs multMatrizPar}
    \label{table:matrix_performance}
\end{table}
La tabla proporcionada muestra los tiempos de ejecución de dos implementaciones de multiplicación de matrices, una secuencial (\texttt{mulMatriz}) y otra paralela (\texttt{multMatrizPar}), para diferentes tamaños de matrices, expresados como potencias de 2. Además, se presenta el \textit{speedup} de la versión paralela en comparación con la secuencial. A continuación, se analizan diversos aspectos de estas implementaciones:

\begin{enumerate}
  \item \textbf{¿Cuál de las implementaciones es más rápida?} \\
  Para matrices de tamaño pequeño (hasta $2^6$), la versión secuencial (\texttt{mulMatriz}) muestra un mejor rendimiento. Sin embargo, a partir de matrices de tamaño $2^7$, la implementación paralela (\texttt{multMatrizPar}) empieza a ser más eficiente, superando ligeramente a la versión secuencial en tamaños de $2^{10}$.

  \item \textbf{¿De qué depende que la aceleración sea mejor?} \\
  La aceleración se ve influenciada principalmente por el tamaño de la matriz. Para tamaños pequeños, el \textit{overhead}, en especial el \textit{switch context}, de la paralelización puede no compensar sus beneficios. A medida que el tamaño aumenta, los beneficios del paralelismo superan este \textit{overhead}, resultando en un mejor \textit{speedup}.

  \item \textbf{¿En qué casos es mejor usar la versión secuencial o paralela de cada algoritmo?} \\
  \begin{itemize}
    \item \textbf{Versión Secuencial (\texttt{mulMatriz}):} Ideal para matrices pequeñas (hasta $2^6$), donde el \textit{overhead} del paralelismo no se justifica.
    \item \textbf{Versión Paralela (\texttt{multMatrizPar}):} Recomendada para matrices de gran tamaño (a partir de $2^7$), donde el coste del paralelismo se ve compensado por la eficiencia en el procesamiento de grandes volúmenes de datos.
  \end{itemize}
\end{enumerate}

\begin{table}[h]
    \centering
    \begin{tabular}{ | m{2cm} | m{4cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & mulMatrizRecPar(ms) & multStrassen(ms) & speedup \\ 
    \hline
    $n^0$ & 0.0882 & 0.0248 & 3.56 \\
    $n^1$ & 0.2109 & 0.1308 & 1.61 \\
    $n^2$ & 0.3769 & 0.4245 & 0.89 \\
    $n^3$ & 0.9086 & 1.5833 & 0.57 \\
    $n^4$ & 0.8598 & 4.6825 & 0.18 \\
    $n^5$ & 17.6741 & 30.5887 & 0.58 \\
    $n^6$ & 51.2801 & 232.0896 & 0.22 \\
    $n^7$ & 389.73 & 1692.9611 & 0.23 \\
    $n^8$ & 3114.4097 & 5199.9472 & 0.60 \\
    \hline
    \end{tabular}
    \caption{mulMatrizRecPar vs multStrassen}
    \label{table:matrix_performance}
\end{table}



\begin{table}[h]
    \centering
    \begin{tabular}{ | m{2cm} | m{4cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & mulMatrizRec(ms) & multStrassenPar(ms) & speedup \\ 
    $n^0$ & 0.0541 & 0.035 & 1.55 \\
    $n^1$ & 0.033 & 0.2113 & 0.16 \\
    $n^2$ & 0.1192 & 0.33 & 0.36 \\
    $n^3$ & 0.5392 & 2.0168 & 0.27 \\
    $n^4$ & 1.1699 & 5.0879 & 0.23 \\
    $n^5$ & 8.4393 & 11.5936 & 0.73 \\
    $n^6$ & 67.8253 & 64.9989 & 1.04 \\
    $n^7$ & 567.7783 & 451.8261 & 1.26 \\
    \hline
    \end{tabular}
    \caption{mulMatrizRec vs multStrassenPar}
    \label{table:matrix_performance}
\end{table}   

\begin{table}[h]
\centering
    \begin{tabular}{ | m{2cm} | m{4cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & multMatrizRec(ms) & multStrassen(ms) & Speedup \\ 
    \hline
    $n^0$ & 0.0195 & 0.0129 & 1.51 \\
    $n^1$ & 0.0584 & 0.0403 & 1.45 \\
    $n^2$ & 0.0926 & 0.3343 & 0.28 \\
    $n^3$ & 0.6009 & 0.9823 & 0.61 \\
    $n^4$ & 1.2007 & 2.0959 & 0.57 \\
    $n^5$ & 5.8948 & 10.1365 & 0.58 \\
    $n^6$ & 49.869 & 70.9033 & 0.70 \\
    $n^7$ & 415.2096 & 529.4741 & 0.78 \\
    $n^8$ & 3099.9929 & 3523.037 & 0.88 \\
    $n^9$ & 25379.6906 & 25235.8456 & 1.01 \\
    \hline
    \end{tabular}
    \caption{multMatrizRec vs multStrassen}
    \label{table:matrix_comparison}
\end{table} 


\begin{table}[h]
    \centering
    \begin{tabular}{ | m{4cm} | m{4cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & multMatrizRec(ms) & multMatrizRecPar(ms) & Speedup \\ 
    \hline
    $n^0$ & 0.0535 & 0.0495 & 1.08 \\
    $n^1$ & 0.0632 & 0.1054 & 0.60 \\
    $n^2$ & 0.1286 & 0.1518 & 0.85 \\
    $n^3$ & 0.403 & 0.4911 & 0.82 \\
    $n^4$ & 5.5323 & 3.9688 & 1.39 \\
    $n^5$ & 8.5952 & 4.7139 & 1.82 \\
    $n^6$ & 67.7342 & 37.6179 & 1.80 \\
    $n^7$ & 551.341 & 300.7862 & 1.83 \\
    $n^8$ & 4441.5969 & 2399.4469 & 1.85 \\
    \hline
    \end{tabular}
    \caption{multMatrizRec vs multMatrizRecPar}
    \label{table:matrix_comparison}
\end{table}


\begin{table}[h]
    \centering
    \begin{tabular}{ | m{2cm} | m{3cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & multMatriz(ms) & multMatrizPar(ms) & Speedup \\ 
    \hline
    $n^0$ & 0.157074 & 0.508098 & 0.31 \\
    $n^1$ & 0.058667 & 0.259741 & 0.23 \\
    $n^2$ & 0.06202 & 0.304369 & 0.20 \\
    $n^3$ & 0.241862 & 0.186058 & 1.30 \\
    $n^4$ & 1.196248 & 0.536174 & 2.23 \\
    $n^5$ & 15.896863 & 2.565981 & 6.20 \\
    $n^6$ & 234.5659 & 21.393817 & 10.96 \\
    $n^7$ & 3373.980202 & 374.861453 & 9.00 \\
    $n^8$ & 52778.116937 & 10691.328672 & 4.94 \\
    \hline
    \end{tabular}
    \caption{multMatriz vs multMatrizPar}
    \label{table:matrix_performance}
\end{table}

\begin{table}[h]
\centering
    \begin{tabular}{ | m{4cm} | m{3cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & multMatriz(ms) & multMatrizRec(ms) & Speedup \\ 
    \hline
    $n^0$ & 0.197233 & 0.124877 & 1.58 \\
    $n^1$ & 0.098057 & 0.02626 & 3.73 \\
    $n^2$ & 0.072356 & 0.128369 & 0.56 \\
    $n^3$ & 0.128857 & 0.153372 & 0.84 \\
    $n^4$ & 1.26574 & 0.863941 & 1.47 \\
    $n^5$ & 15.580685 & 6.217719 & 2.51 \\
    $n^6$ & 233.389835 & 57.153132 & 4.08 \\
    $n^7$ & 3756.499596 & 466.273799 & 8.06 \\
    $n^8$ & 74007.560303 & 3649.418623 & 20.28 \\
    \hline
    \end{tabular}
    \caption{multMatriz vs multMatrizRec}
    \label{table:matrix_comparison_rec}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{ | m{2cm} | m{3cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & multMatriz(ms) & multMatrizRecPar(ms) & Speedup \\ 
    \hline
    $n^0$ & 0.213017 & 0.054686 & 3.90 \\
    $n^1$ & 0.05727 & 0.261487 & 0.22 \\
    $n^2$ & 0.093867 & 0.193461 & 0.49 \\
    $n^3$ & 0.138426 & 0.931548 & 0.15 \\
    $n^4$ & 1.035612 & 0.553565 & 1.87 \\
    $n^5$ & 15.601226 & 4.07065 & 3.83 \\
    $n^6$ & 260.689531 & 30.724248 & 8.48 \\
    $n^7$ & 4699.357314 & 223.874599 & 20.99 \\
    $n^8$ & 94123.683973 & 1796.040497 & 52.41 \\
    \hline
    \end{tabular}
    \caption{multMatriz vs multMatrizRecPar}
    \label{table:matrix_comparison_rec_par}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{ | m{2cm} | m{3cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & multMatriz(ms) & multStrassenPar(ms) & Speedup \\ 
    \hline
    $n^0$ & 0.0271 & 0.0113 & 2.40 \\
    $n^1$ & 0.05 & 0.0886 & 0.56 \\
    $n^2$ & 0.0298 & 0.1949 & 0.15 \\
    $n^3$ & 0.1785 & 0.687 & 0.26 \\
    $n^4$ & 0.9352 & 2.2692 & 0.41 \\
    $n^5$ & 10.9968 & 4.8675 & 2.26 \\
    $n^6$ & 199.8272 & 38.1879 & 5.23 \\
    $n^7$ & 3721.3193 & 240.8355 & 15.45 \\
    $n^8$ & 77156.0959 & 1724.9942 & 44.73 \\
    \hline
    \end{tabular}
    \caption{multMatriz vs multStrassenPar}
    \label{table:matrix_comparison_strassen_par}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{ | m{2cm} | m{3cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & multStrassen(ms) & multMatrizPar(ms) & Speedup \\ 
    \hline
    $n^0$ & 0.0187 & 0.0708 & 0.26 \\
    $n^1$ & 0.0472 & 0.0979 & 0.48 \\
    $n^2$ & 0.1763 & 0.1098 & 1.61 \\
    $n^3$ & 1.4824 & 0.1596 & 9.29 \\
    $n^4$ & 1.3893 & 0.2277 & 6.10 \\
    $n^5$ & 10.0845 & 2.1428 & 4.71 \\
    $n^6$ & 71.4526 & 39.3428 & 1.82 \\
    $n^7$ & 524.8294 & 660.7993 & 0.79 \\
    $n^8$ & 3715.7102 & 13099.9935 & 0.28 \\
    \hline
    \end{tabular}
    \caption{multStrassen vs multMatrizPar}
    \label{table:matrix_comparison_strassen_matrizpar}
\end{table}


\begin{table}[h]
    \centering
    \begin{tabular}{ | m{2cm} | m{3cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & multStrassen(ms) & multStrassenPar(ms) & Speedup \\ 
    \hline
    $n^0$ & 0.094566 & 0.018089 & 5.23 \\
    $n^1$ & 0.164617 & 0.266935 & 0.62 \\
    $n^2$ & 0.082203 & 0.486237 & 0.17 \\
    $n^3$ & 0.551889 & 0.492383 & 1.12 \\
    $n^4$ & 2.002918 & 2.132335 & 0.94 \\
    $n^5$ & 11.121369 & 9.672645 & 1.15 \\
    $n^6$ & 83.202037 & 56.999489 & 1.46 \\
    $n^7$ & 591.982072 & 397.681511 & 1.49 \\
    $n^8$ & 4214.366236 & 2770.456839 & 1.52 \\
    \hline
    \end{tabular}
    \caption{multStrassen vs multStrassenPar}
    \label{table:strassen_comparison}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{ | m{2cm} | m{4cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & multMatrizRec(ms) & multMatrizPar(ms) & Speedup \\ 
    \hline
    $n^0$ & 0.069562 & 0.198001 & 0.35 \\
    $n^1$ & 0.046654 & 0.318967 & 0.15 \\
    $n^2$ & 0.501463 & 0.312541 & 1.60 \\
    $n^3$ & 0.171252 & 0.516339 & 0.33 \\
    $n^4$ & 0.914017 & 0.475552 & 1.92 \\
    $n^5$ & 6.9931 & 2.383554 & 2.93 \\
    $n^6$ & 52.731112 & 44.138359 & 1.19 \\
    $n^7$ & 459.95615 & 668.513945 & 0.69 \\
    $n^8$ & 3509.126971 & 13464.049988 & 0.26 \\
    \hline
    \end{tabular}
    \caption{multMatrizRec vs multMatrizPar}
    \label{table:matrix_comparison_rec_par}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{ | m{2cm} | m{4cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & multStrassenPar(ms) & multMatrizPar(ms) & Speedup \\ 
    \hline
    $n^0$ & 0.0183 & 0.0677 & 0.27 \\
    $n^1$ & 0.068 & 0.0845 & 0.80 \\
    $n^2$ & 0.1879 & 0.1407 & 1.34 \\
    $n^3$ & 0.6789 & 0.2121 & 3.20 \\
    $n^4$ & 2.3105 & 0.4184 & 5.52 \\
    $n^5$ & 5.0187 & 2.1041 & 2.39 \\
    $n^6$ & 35.2597 & 41.5603 & 0.85 \\
    $n^7$ & 254.7461 & 671.1146 & 0.38 \\
    $n^8$ & 1759.3622 & 13238.1516 & 0.13 \\
    \hline
    \end{tabular}
    \caption{multStrassenPar vs multMatrizPar}
    \label{table:strassen_par_matrix_par_comparison}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{ | m{2cm} | m{4cm} | m{4cm} | m{3cm} | }
    \hline
    Matrix size & multMatrizRecPar(ms) & multMatrizPar(ms) & Speedup \\ 
    \hline
    $n^0$ & 0.0702 & 0.0311 & 2.26 \\
    $n^1$ & 0.0424 & 0.1279 & 0.33 \\
    $n^2$ & 0.0463 & 0.1546 & 0.30 \\
    $n^3$ & 0.2225 & 0.7962 & 0.28 \\
    $n^4$ & 1.8466 & 2.8966 & 0.64 \\
    $n^5$ & 19.7595 & 14.4537 & 1.37 \\
    $n^6$ & 325.1826 & 104.5296 & 3.11 \\
    $n^7$ & 5908.247 & 727.7273 & 8.12 \\
    $n^8$ & 114646.5989 & 5121.9016 & 22.38 \\
    \hline
    \end{tabular}
    \caption{multMatrizRecPar vs multMatrizPar}
    \label{table:rec_par_matrix_par_comparison}
\end{table}

\subsubsection{Metodología de Generación de Matrices de Prueba}
Descripción de cómo se generaron las matrices de prueba.
\subsubsection{Análisis de Resultados}
Análisis profundo de los resultados obtenidos.

\subsubsection{Resultados de Producto Punto de Vectores}
Tabla comparativa y análisis de desempeño para las implementaciones de producto punto.
\subsubsection{Impacto de las Dimensiones de los Vectores}
Discusión sobre cómo las dimensiones de los vectores afectan al desempeño.
\subsubsection{Análisis de Resultados del Producto Punto}
Análisis detallado de los resultados del producto punto.

\subsection{Análisis comparativo de las diferentes soluciones}
\subsubsection{Análisis Basado en Resultados}
Comparación entre las versiones secuenciales y paralelas de los algoritmos y su desempeño.
\subsubsection{Eficiencia del Algoritmo de Strassen}
Discusión específica sobre la eficiencia del algoritmo de Strassen en comparación con otros.
\subsubsection{Reflexiones sobre el Paralelismo}
Evaluación crítica del paralelismo de tareas y de datos y su efecto en la eficiencia general.

\section{Conclusiones}
\subsection{Síntesis de Hallazgos}
Resumen de los hallazgos más importantes del informe.
\subsection{Implicaciones de los Resultados}
Discusión sobre las implicaciones de los resultados para futuras investigaciones y aplicaciones prácticas.
\subsection{Recomendaciones}
Recomendaciones basadas en el análisis y desempeño de las funciones estudiadas.

\end{document}